# -*- coding: utf-8 -*-
"""a01745914_Momento de Retro:Modulo2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C8BAHwpSPl3ys3rQcN55XPHie7_RxKyW

#Momento de Retroalimentación: Módulo 2 Implementación de una técnica de aprendizaje máquina sin el uso de un framework

##Naomi Padilla Mora A01745914

https://colab.research.google.com/drive/1C8BAHwpSPl3ys3rQcN55XPHie7_RxKyW?usp=sharing

El siguiente modelo tiene por objetivo predecir el Spending Score al que pertenece un cliente dependiendo de su género, edad e ingreso anual.

#Librerias
"""

import pandas as pd
import numpy as np
from pandas import read_csv
import seaborn as sns

"""#Tratamiento de los datos"""

#colocar path del csv. Click derecho, copy path
df = pd.read_csv("/Users/naomipadilla/Downloads/Momento de Retro Mod2/Mall_Customers.csv", header=0)
df

#Nos aseguramos que no hay valores nulos en la base de datos
df.isna().sum()

#cambiamos el género por 1(Masculino) y 0(Femenino) de tal forma que solo tengamos variables numéricas en el dataset.
df["Gender"]=df["Gender"].replace(['Male'],'1')
df["Gender"]=df["Gender"].replace(['Female'],'0')
df

df['Gender'] = df['Gender'].astype('Int64')

df.dtypes

#eliminamos la columna customerID
df.drop(["CustomerID"], axis=1, inplace=True)

sns.heatmap(df.corr(), annot=True)

"""#Decision Tree

##Separación de los datos en train y test.
"""

from sklearn.model_selection import train_test_split
train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)

X_train = train_data[["Gender", "Age", "Annual Income (k$)"]].values
y_train = train_data["Spending Score (1-100)"].values
X_test = test_data[["Gender", "Age", "Annual Income (k$)"]].values
y_test = test_data["Spending Score (1-100)"].values

"""##Índice de Gini

Función: **calcular_gini(labels)** recibe el ejemplo de una etiqueta (variable) o condición sobre alguna varible del dataset con el objetivo de regresar el valor de gini. El cual es un coeficiente de pureza de los datos. Esta función se implementará en la creación del árbol de manera que selecciona el valor total de gini segun los parámetos dados.
"""

#solo correr
def calcular_gini(labels):
    total = len(labels)
    conteo_clases = {}

    for label in labels:
        if label not in conteo_clases:
            conteo_clases[label] = 0
        conteo_clases[label] += 1

    impureza_gini = 1.0
    for clase, conteo in conteo_clases.items():
        probabilidad = conteo / total
        impureza_gini -= probabilidad ** 2

    return impureza_gini

#de desear probar solo la función, correr las siguientes líneas
#etiquetas = train_data["etiqueta"] < 20  # Reemplaza 'etiqueta' por el nombre de tu columna
#gini_value = calcular_gini(etiquetas)
#gini_value

"""##Creación del modelo - árbol

Función: **dividir_datos(data,columna, valor)** esta función es para dividir los datos en ramas basadas en diferentes características y valores.


"""

#solo correr
def dividir_datos(data, columna, valor):
    izquierda, derecha = [], []
    for fila in data:
        if fila[columna] <= valor:
            izquierda.append(fila)
        else:
            derecha.append(fila)
    return izquierda, derecha

#construcción del arbol, recibe el df y la profundidad deseada del árbol
def construir_arbol(data, profundidad_maxima):
    if profundidad_maxima == 0:
        etiquetas = [fila[-1] for fila in data]
        return max(etiquetas, key=etiquetas.count)

    mejor_gini = float('inf')
    mejor_division = None

    for columna in range(len(data[0]) - 1):
        for fila in data:
            izquierda, derecha = dividir_datos(data, columna, fila[columna])

            if not izquierda or not derecha:
                continue

            gini_total = (len(izquierda) / len(data)) * calcular_gini([fila[-1] for fila in izquierda]) + \
                         (len(derecha) / len(data)) * calcular_gini([fila[-1] for fila in derecha])

            if gini_total < mejor_gini:
                mejor_gini = gini_total
                mejor_division = (columna, fila[columna])

    if mejor_gini == float('inf'):
        etiquetas = [fila[-1] for fila in data]
        return max(etiquetas, key=etiquetas.count)

    izquierda, derecha = dividir_datos(data, *mejor_division)
    nodo = {'columna': mejor_division[0], 'valor': mejor_division[1]}
    nodo['izquierda'] = construir_arbol(izquierda, profundidad_maxima - 1)
    nodo['derecha'] = construir_arbol(derecha, profundidad_maxima - 1)
    return nodo

#esta es la función que nos permite probar el árbol y clasificar el ejemplo que se le de
def clasificar_ejemplo(ejemplo, arbol):
    if isinstance(arbol, int):
        return arbol

    columna, valor = arbol['columna'], arbol['valor']
    if ejemplo[columna] <= valor:
        return clasificar_ejemplo(ejemplo, arbol['izquierda'])
    else:
        return clasificar_ejemplo(ejemplo, arbol['derecha'])

#Entrenamiento del modelo
from sklearn.metrics import accuracy_score

arbol = construir_arbol(np.column_stack((X_train, y_train)), profundidad_maxima=3)

#Evaluación del modelo
predicciones = [clasificar_ejemplo(ejemplo, arbol) for ejemplo in X_test]

# Precisión del modelo
precision = accuracy_score(y_test, predicciones)
print("Precisión del modelo:", precision)

"""#Evaluación del modelo con profundidad máx = 3
Precisión: 0.033333...

Valores ejemplo(Género, edad, ingreso anual) - cliente 0 : [1,24,60]

Valor real del Spending Score : 52


"""

X_test[0]

y_test[0]

# Creación del árbol
arbol = construir_arbol(np.column_stack((X_train, y_train)), profundidad_maxima=3)


#CAMBIAR VALORES A LOS DESEADOS
# Ejemplo de clasificación
#G =  (0 - F, 1 - M), E = edad, I = ingreso anual]
ejemplo = X_test[0] #array con [G,E,I]
resultado = clasificar_ejemplo(ejemplo, arbol)
print("Resultado de clasificación:", resultado)

"""Comprobamos que la predicción no es acertada y buscamos mejorar el modelo."""

arbol = construir_arbol(np.column_stack((X_train, y_train)), profundidad_maxima=4)

#Evaluación del modelo
predicciones = [clasificar_ejemplo(ejemplo, arbol) for ejemplo in X_test]

# Precisión del modelo
precision = accuracy_score(y_test, predicciones)
print("Precisión del modelo:", precision)

"""#Evaluación del modelo con profundidad máx = 4
Precisión: 0.016666...

Valores ejemplo(Género, edad, ingreso anual) - cliente 1 : [1,22,20]

Valor real del Spending Score : 79

"""

X_test[1]

y_test[1]

# Creación del árbol
arbol = construir_arbol(np.column_stack((X_train, y_train)), profundidad_maxima=4)

# Ejemplo de clasificación
#G = género (0 - Fem, 1 - Male), E = edad, I = ingreso anual (0-100)]
ejemplo = X_test[1] #array con [G,E,I]
resultado = clasificar_ejemplo(ejemplo, arbol)
print("Resultado de clasificación:", resultado)

"""El modelo no presenta mejoras al incrementar la máx profundidad."""